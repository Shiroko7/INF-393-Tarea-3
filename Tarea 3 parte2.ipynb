{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> Tarea 3 - Ensamblados y modelos avanzados</h1>\n",
    "\n",
    "<H3 align='center'> <i>Felipe Olavarria, Rol:201673606-9</i> </H3>\n",
    "<H3 align='center'> <i>Jean Aravena, Rol:201673573-9</i> </H3>\n",
    "<hr style=\"height:2px;border:none\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re, time\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from  sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Detección de acoso en *Twitter*\n",
    "---\n",
    "En las redes sociales muchas veces se encuentra con un cierto comportamiento indeseable para los usuarios, tal como racismo, misógeno, grupos de odio o *trolls*. El poder detectar de manera automática ciertos patrones en el comportamiento para tomar una acción debe ser crucial para reducir el tiempo y esfuerzo humano. En esta actividad se trabajará sobre *tweets* la red social de *twitter* para detectar comportamiento *online* de acoso (*harassment*), que por lo general, incluye *flaming* como lenguaje abusivo o insultos, *doxing* como mostrar la información personal de una mujer, por ejemplo el domicilio o número de teléfono, la suplantación o la vergüenza pública por destruir la reputación de las personas.\n",
    "\n",
    "<img src=\"https://kidshelpline.com.au/sites/default/files/bdl_image/header-T-OH.png\" title=\"Title text\" width=\"45%\"  />\n",
    "\n",
    "En algunos problemas como este, el comportamiento a detectar puede ser asociado a una anomalía (*outlier*) del comportamiento normal de los usuarios en las redes sociales. Esto es una de las causas de la dificultad del problema, puesto que es **altamente desbalanceado**, donde aproximadamente un 10% de los *tweets* corresponden a acoso (*harassment*).\n",
    "\n",
    "Los datos trabajados corresponderan a *tweets* etiquetados como *harassment* (con valor 1) o no (con valor 0) -- la tarea a detectar--. Además si desea utilizar, se incluye la información del tipo de *harassment* en el conjunto de entrenamiento como atributos extras. El conjunto de pruebas solo contiene los *tweets* a ser etiquetados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_content</th>\n",
       "      <th>harassment</th>\n",
       "      <th>IndirectH</th>\n",
       "      <th>PhysicalH</th>\n",
       "      <th>SexualH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9565</td>\n",
       "      <td>also released this video of photos voyager too...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6794</td>\n",
       "      <td>Yeah sexting older games until x89 teach doug...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4337</td>\n",
       "      <td>ava There s likely hundreds of stories like t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6621</td>\n",
       "      <td>Wonder if there is significance to having Ava ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3289</td>\n",
       "      <td>i m a slut for guacamole an avocadhoe if you will</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                      tweet_content  harassment  \\\n",
       "0  9565  also released this video of photos voyager too...           0   \n",
       "1  6794   Yeah sexting older games until x89 teach doug...           0   \n",
       "2  4337   ava There s likely hundreds of stories like t...           0   \n",
       "3  6621  Wonder if there is significance to having Ava ...           0   \n",
       "4  3289  i m a slut for guacamole an avocadhoe if you will           0   \n",
       "\n",
       "   IndirectH  PhysicalH  SexualH  \n",
       "0          0          0        0  \n",
       "1          0          0        0  \n",
       "2          0          0        0  \n",
       "3          0          0        0  \n",
       "4          0          0        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train df\n",
    "df_train = pd.read_csv(\"Train_data.csv\")\n",
    "\n",
    "df_train_text = df_train.tweet_content\n",
    "\n",
    "labels_train_indirect = df_train.IndirectH\n",
    "labels_train_physical = df_train.PhysicalH\n",
    "labels_train_sexual = df_train.SexualH\n",
    "\n",
    "labels_train = df_train.harassment\n",
    "#Test df\n",
    "df_test = pd.read_csv(\"Test_input.csv\")\n",
    "df_test_text = df_test.tweet_content\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n",
      "112\n",
      "311\n"
     ]
    }
   ],
   "source": [
    "print(df_train[df_train['IndirectH'] == 1].shape[0])\n",
    "print(df_train[df_train['PhysicalH'] == 1].shape[0])\n",
    "print(df_train[df_train['SexualH'] == 1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5703 entries, 0 to 5702\n",
      "Data columns (total 6 columns):\n",
      "id               5703 non-null int64\n",
      "tweet_content    5703 non-null object\n",
      "harassment       5703 non-null int64\n",
      "IndirectH        5703 non-null int64\n",
      "PhysicalH        5703 non-null int64\n",
      "SexualH          5703 non-null int64\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 267.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tenemos 5703 datos diferentes en el dataset, cada uno con 6 atributos. Se muestra el resumen del dataframe, en el cual no existen registros nulos para ninguna de las 6 columnas.\n",
    "Además se informa el tipo de dato que presenta cada una de los atributos y la memoria utilizada.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "c = df_train.shape[0]\n",
    "d = int(c * 0.2)\n",
    "\n",
    "df_train_text,df_val_text,labels_train_indirect,labels_val_indirect,labels_train_physical,labels_val_physical,labels_train_sexual,labels_val_sexual,labels_train,labels_val  = train_test_split(df_train_text, labels_train_indirect,labels_train_physical,labels_train_sexual,labels_train, test_size = d, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***El tamaño de entrenamiento correspondera al 80% de los datos.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Se realiza un pre-procesamiento a los textos para normalizar un poco su estructura, donde se pasa el texto a minúsculas (lower-casing), se reducen las mútliples letras, se eliminan palabras sin significados como artículos, pronombres y preposiciones (stop word removal), además de pasar las palabras a su tronco léxico con la técnica de lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_word(word):\n",
    "    wordlemmatizer = WordNetLemmatizer()\n",
    "    return wordlemmatizer.lemmatize(word) \n",
    "def word_extractor(text):\n",
    "    commonwords = stopwords.words('english')\n",
    "    text = re.sub(r'([a-z])\\1+', r'\\1\\1',text) #substitute multiple letter by two\n",
    "    words = \"\"\n",
    "    wordtokens = [ base_word(word.lower()) for word in word_tokenize(text) ]\n",
    "    for word in wordtokens:\n",
    "        if word not in commonwords: #delete stopwords\n",
    "            words+=\" \"+word\n",
    "    return words\n",
    "\n",
    "texts_train = [word_extractor(text) for text in df_train_text]\n",
    "\n",
    "texts_val = [word_extractor(text) for text in df_val_text]\n",
    "\n",
    "texts_test = [word_extractor(text) for text in df_test_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Se construye una representación vectorial a los textos de entrada para poder ser manejados y clasificados por los modelos de aprendizaje. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(binary=False, ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, norm='l2', use_idf=True, sublinear_tf=False)\n",
    "vectorizer.fit(texts_train)\n",
    "\n",
    "\n",
    "features_train = vectorizer.transform(texts_train)\n",
    "features_val = vectorizer.transform(texts_val)\n",
    "features_test = vectorizer.transform(texts_test)\n",
    "\n",
    "\n",
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***La manera de trabajar el problema sera haciendo modelos especializados en clasificar cada tipos de acoso, para luego juntar estas predicciones en una gran clase de acoso. Por lo que se entrenaran a parte cada modelo y se búscaran hiper-párametros que maximizen el F-score. Esto se repitira para una serie de modelos estudiados durante el curso.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 indirect newton-cg 0.0001\n",
      "0.13333333333333333 indirect newton-cg 10\n",
      "0.16666666666666666 indirect lbfgs 1000000\n",
      " \n",
      "0.0 physical newton-cg 0.0001\n",
      "0.12121212121212122 physical newton-cg 10\n",
      "0.2702702702702703 physical newton-cg 100\n",
      "0.3157894736842105 physical newton-cg 1000000\n",
      " \n",
      "0.0 sexual newton-cg 0.0001\n",
      "0.14492753623188404 sexual newton-cg 1\n",
      "0.4742268041237113 sexual newton-cg 10\n",
      "0.4807692307692307 sexual newton-cg 100000\n",
      "0.4952380952380952 sexual newton-cg 1000000\n",
      "0.5 sexual liblinear 100000\n",
      "0.505050505050505 sexual saga 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4277456647398844"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def do_logit(x_,y_indirect,y_physical,y_sexual,features_val):\n",
    "    Cs = [10**i for i in range(-4,7)]\n",
    "    Ss = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "    f_max=-1\n",
    "    for s in Ss:\n",
    "        for i in Cs:\n",
    "            model_1 = LogisticRegression(multi_class='auto',penalty='l2',max_iter=1000,solver = s)\n",
    "            model_1.set_params(C=i)\n",
    "            model_1.fit(x_,y_indirect)\n",
    "            pred_i = model_1.predict(features_val)\n",
    "            f_i = f1_score(labels_val_indirect, pred_i, average='binary')\n",
    "            if f_i > f_max:\n",
    "                print(f_i, 'indirect',s,i)\n",
    "                f_max = f_i\n",
    "                pred_1 = pred_i\n",
    "    print(' ')\n",
    "    f_max=-1\n",
    "    for s in Ss:\n",
    "        for i in Cs:\n",
    "            model_2 = LogisticRegression(multi_class='auto',penalty='l2',max_iter=1000,solver = s)\n",
    "            model_2.set_params(C=i)\n",
    "            model_2.fit(x_,y_physical)\n",
    "            pred_i = model_2.predict(features_val)\n",
    "            f_i = f1_score(labels_val_physical, pred_i, average='binary')\n",
    "            if f_i > f_max:\n",
    "                print(f_i, 'physical',s,i)\n",
    "                f_max = f_i\n",
    "                pred_2 = pred_i\n",
    "    print(' ')\n",
    "    f_max=-1\n",
    "    for s in Ss:\n",
    "        for i in Cs:\n",
    "            model_3 = LogisticRegression(multi_class='auto',penalty='l2',max_iter=1000,solver = s)\n",
    "            model_3.set_params(C=i)\n",
    "            model_3.fit(x_,y_sexual)\n",
    "            pred_i = model_3.predict(features_val)\n",
    "            f_i = f1_score(labels_val_sexual, pred_i, average='binary')\n",
    "            if f_i > f_max:\n",
    "                print(f_i, 'sexual',s,i)\n",
    "                f_max = f_i\n",
    "                pred_3 = pred_i\n",
    "\n",
    "    return pred_1,pred_2,pred_3\n",
    "    \n",
    "y_pred_logit_1,y_pred_logit_2,y_pred_logit_3 = do_logit(features_train,labels_train_indirect,labels_train_physical,labels_train_sexual,features_val)\n",
    "\n",
    "y_pred_logit = y_pred_logit_1 | y_pred_logit_2 | y_pred_logit_3 \n",
    "f1_score(labels_val, y_pred_logit, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 indirect linear 0.0001\n",
      "0.21052631578947367 indirect linear 10\n",
      " \n",
      "0.0 physical linear 0.0001\n",
      "0.125 physical linear 1\n",
      "0.3157894736842105 physical linear 10\n",
      " \n",
      "0.0 sexual linear 0.0001\n",
      "0.3777777777777777 sexual linear 1\n",
      "0.47368421052631576 sexual linear 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4526315789473685"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC as SVM #SVC is for classification\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def do_svm(x_,y_indirect,y_physical,y_sexual,features_val):\n",
    "    Cs = [10**i for i in range(-4,7)]\n",
    "    Ks = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    f_max=-1\n",
    "    for k in Ks:\n",
    "        for i in Cs:\n",
    "            model_1 = SVM(kernel=k,gamma='scale')\n",
    "            model_1.set_params(C=i)\n",
    "            model_1.fit(x_,y_indirect)\n",
    "            pred_i = model_1.predict(features_val)\n",
    "            f_i = f1_score(labels_val_indirect, pred_i, average='binary')\n",
    "            if f_i > f_max:\n",
    "                f_max = f_i\n",
    "                pred_1 = pred_i\n",
    "                print(f_i, 'indirect',k,i)\n",
    "    print(' ')\n",
    "    f_max=-1\n",
    "    for k in Ks:\n",
    "        for i in Cs:\n",
    "            model_2 = SVM(kernel=k,gamma='scale')\n",
    "            model_2.set_params(C=i)\n",
    "            model_2.fit(x_,y_physical)\n",
    "            pred_i = model_2.predict(features_val)\n",
    "            f_i = f1_score(labels_val_physical, pred_i, average='binary')\n",
    "            if f_i > f_max:\n",
    "                f_max = f_i\n",
    "                pred_2 = pred_i\n",
    "                print(f_i, 'physical',k,i)\n",
    "    print(' ')\n",
    "    f_max=-1\n",
    "    for k in Ks:\n",
    "        for i in Cs:\n",
    "            model_3 = SVM(kernel=k,gamma='scale')\n",
    "            model_3.set_params(C=i)\n",
    "            model_3.fit(x_,y_sexual)\n",
    "            pred_i = model_3.predict(features_val)\n",
    "            f_i = f1_score(labels_val_sexual, pred_i, average='binary')\n",
    "            if f_i > f_max:\n",
    "                f_max = f_i\n",
    "                pred_3 = pred_i\n",
    "                print(f_i, 'sexual',k,i)\n",
    "    \n",
    "    return pred_1,pred_2,pred_3\n",
    "    \n",
    "y_pred_svm_1,y_pred_svm_2,y_pred_svm_3 = do_svm(features_train,labels_train_indirect,labels_train_physical,labels_train_sexual,features_val)\n",
    "\n",
    "y_pred_svm = y_pred_svm_1 | y_pred_svm_2 | y_pred_svm_3\n",
    "\n",
    "f1_score(labels_val, y_pred_svm, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árbol regularizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 indirect 1 2\n",
      "0.18750000000000003 indirect 5 2\n",
      "0.2222222222222222 indirect 9 6\n",
      "0.2702702702702703 indirect 15 11\n",
      " \n",
      "0.12903225806451613 physical 1 2\n",
      "0.16666666666666666 physical 3 3\n",
      "0.21052631578947364 physical 8 8\n",
      "0.24390243902439027 physical 14 12\n",
      " \n",
      "0.0 sexual 1 2\n",
      "0.03125 sexual 7 2\n",
      "0.031746031746031744 sexual 7 3\n",
      "0.03278688524590164 sexual 7 13\n",
      "0.061538461538461535 sexual 8 32\n",
      "0.0625 sexual 11 35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18840579710144928"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree\n",
    "def do_Tree(x_,y_indirect,y_physical,y_sexual,features_val):\n",
    "    Ds = np.arange(1, 25, 1)\n",
    "    Ss = np.arange(2, 40, 1)\n",
    "    f_max=-1\n",
    "    for d in Ds:\n",
    "        for s in Ss:\n",
    "            model_1= Tree()\n",
    "            model_1.set_params(max_depth=d, min_samples_split=s) \n",
    "            model_1.fit(x_,y_indirect)\n",
    "            pred_i = model_1.predict(features_val)\n",
    "            f_i = f1_score(labels_val_indirect, pred_i, average='binary')\n",
    "            if f_i > f_max:\n",
    "                f_max = f_i\n",
    "                pred_1 = pred_i\n",
    "                print(f_i, 'indirect',d,s)     \n",
    "    print(' ')           \n",
    "    f_max=-1\n",
    "    for d in Ds:\n",
    "        for s in Ss:\n",
    "            model_2= Tree()\n",
    "            model_2.set_params(max_depth=d, min_samples_split=s) \n",
    "            model_2.fit(x_,y_physical)\n",
    "            pred_i = model_2.predict(features_val)\n",
    "            f_i = f1_score(labels_val_physical, pred_i, average='binary')\n",
    "            if f_i > f_max:\n",
    "                f_max = f_i\n",
    "                pred_2 = pred_i\n",
    "                print(f_i, 'physical',d,s)  \n",
    "    print(' ')\n",
    "    f_max=-1\n",
    "    for d in Ds:\n",
    "        for s in Ss:\n",
    "            model_3= Tree()\n",
    "            model_3.set_params(max_depth=d, min_samples_split=s) \n",
    "            model_3.fit(x_,y_indirect)\n",
    "            pred_i = model_3.predict(features_val)\n",
    "            f_i = f1_score(labels_val_sexual, pred_i, average='binary')\n",
    "            if f_i > f_max:\n",
    "                f_max = f_i\n",
    "                pred_3 = pred_i\n",
    "                print(f_i, 'sexual',d,s)  \n",
    "            \n",
    "    return pred_1,pred_2,pred_3\n",
    "\n",
    "y_pred_tree_1,y_pred_tree_2,y_pred_tree_3 = do_Tree(features_train,labels_train_indirect,labels_train_physical,labels_train_sexual,features_val)\n",
    "\n",
    "y_pred_tree  = y_pred_tree_1 | y_pred_tree_2 | y_pred_tree_3 \n",
    "\n",
    "f1_score(labels_val, y_pred_tree, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 indirect 1\n",
      " \n",
      "0.06451612903225806 physical 1\n",
      " \n",
      "0.08571428571428572 sexual 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10144927536231883"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def do_rf(x_,y_indirect,y_physical,y_sexual,features_val):\n",
    "    Cs = [2**i for i in range(8)]\n",
    "    f_max=-1\n",
    "    for i in Cs:\n",
    "        model_1 = RandomForestClassifier(n_estimators=i,max_depth=12,min_samples_split=10,random_state=0,n_jobs=-1)\n",
    "        model_1.fit(x_,y_indirect)\n",
    "        pred_i = model_1.predict(features_val)\n",
    "        f_i = f1_score(labels_val_indirect, pred_i, average='binary')\n",
    "        if f_i > f_max:\n",
    "            f_max = f_i\n",
    "            pred_1 = pred_i\n",
    "            print(f_i, 'indirect',i)\n",
    "    print(' ')    \n",
    "    f_max=-1\n",
    "    for i in Cs:\n",
    "        model_2 = RandomForestClassifier(n_estimators=i,max_depth=7,min_samples_split=40,random_state=0,n_jobs=-1)\n",
    "        model_2.fit(x_,y_physical)\n",
    "        pred_i = model_2.predict(features_val)\n",
    "        f_i = f1_score(labels_val_physical, pred_i, average='binary')\n",
    "        if f_i > f_max:\n",
    "            f_max = f_i\n",
    "            pred_2 = pred_i\n",
    "            print(f_i, 'physical',i)\n",
    "    print(' ')\n",
    "    f_max=-1\n",
    "    for i in Cs:\n",
    "        model_3 = RandomForestClassifier(n_estimators=i,max_depth=13,min_samples_split=25,random_state=0,n_jobs=-1)\n",
    "        model_3.fit(x_,y_sexual)\n",
    "        pred_i = model_3.predict(features_val)\n",
    "        f_i = f1_score(labels_val_sexual, pred_i, average='binary')\n",
    "        if f_i > f_max:\n",
    "            f_max = f_i\n",
    "            pred_3 = pred_i\n",
    "            print(f_i, 'sexual',i)\n",
    "    \n",
    "    return pred_1,pred_2,pred_3\n",
    "    \n",
    "y_pred_rf_1,y_pred_rf_2,y_pred_rf_3 = do_rf(features_train,labels_train_indirect,labels_train_physical,labels_train_sexual,features_val)\n",
    "\n",
    "y_pred_rf = y_pred_rf_1 | y_pred_rf_2 | y_pred_rf_3\n",
    "\n",
    "f1_score(labels_val, y_pred_rf, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19047619047619047 indirect 1\n",
      " \n",
      "0.16216216216216214 physical 1\n",
      "0.21052631578947364 physical 2\n",
      " \n",
      "0.5542168674698795 sexual 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5560165975103736"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def do_gb(x_,y_indirect,y_physical,y_sexual,features_val):\n",
    "    Cs = [2**i for i in range(8)]\n",
    "    f_max=-1\n",
    "    for i in Cs:\n",
    "        model_1 = GradientBoostingClassifier(n_estimators=i, learning_rate=1.0,max_depth=12,min_samples_split=10, random_state=0)\n",
    "        model_1.fit(x_,y_indirect)\n",
    "        pred_i = model_1.predict(features_val)\n",
    "        f_i = f1_score(labels_val_indirect, pred_i, average='binary')\n",
    "        if f_i > f_max:\n",
    "            f_max = f_i\n",
    "            pred_1 = pred_i\n",
    "            print(f_i, 'indirect',i)\n",
    "    print(' ')\n",
    "    f_max=-1\n",
    "    for i in Cs:\n",
    "        model_2 = GradientBoostingClassifier(n_estimators=i, learning_rate=1.0,max_depth=7,min_samples_split=40, random_state=0)\n",
    "        model_2.fit(x_,y_physical)\n",
    "        pred_i = model_2.predict(features_val)\n",
    "        f_i = f1_score(labels_val_physical, pred_i, average='binary')\n",
    "        if f_i > f_max:\n",
    "            f_max = f_i\n",
    "            pred_2 = pred_i\n",
    "            print(f_i, 'physical',i)\n",
    "    print(' ')\n",
    "    f_max=-1\n",
    "    for i in Cs:\n",
    "        model_3 = GradientBoostingClassifier(n_estimators=i, learning_rate=1.0,max_depth=13,min_samples_split=25, random_state=0)\n",
    "        model_3.fit(x_,y_sexual)\n",
    "        pred_i = model_3.predict(features_val)\n",
    "        f_i = f1_score(labels_val_sexual, pred_i, average='binary')\n",
    "        if f_i > f_max:\n",
    "            f_max = f_i\n",
    "            pred_3 = pred_i\n",
    "            print(f_i, 'sexual',i)\n",
    "    \n",
    "    return pred_1,pred_2,pred_3\n",
    "    \n",
    "y_pred_gb_1,y_pred_gb_2,y_pred_gb_3 = do_gb(features_train,labels_train_indirect,labels_train_physical,labels_train_sexual,features_val)\n",
    "\n",
    "y_pred_gb = y_pred_gb_1 | y_pred_gb_2 | y_pred_gb_3\n",
    "\n",
    "f1_score(labels_val, y_pred_gb, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17142857142857143 indirect 1\n",
      " \n",
      "0.16666666666666666 physical 1\n",
      " \n",
      "0.43478260869565216 sexual 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3726708074534162"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def do_ab(x_,y_indirect,y_physical,y_sexual,features_val,labels_val):\n",
    "    Cs = [2**i for i in range(8)]\n",
    "    f_max=-1\n",
    "    for i in Cs:\n",
    "        model_1 = AdaBoostClassifier(base_estimator=Tree(max_depth=12,min_samples_split=10),n_estimators=i,learning_rate=1,random_state=0)\n",
    "        model_1.fit(x_,y_indirect)\n",
    "        pred_i = model_1.predict(features_val)\n",
    "        f_i = f1_score(labels_val_indirect, pred_i, average='binary')\n",
    "        if f_i > f_max:\n",
    "            f_max = f_i\n",
    "            pred_1 = pred_i\n",
    "            print(f_i, 'indirect',i)\n",
    "    print(' ')\n",
    "    f_max=-1\n",
    "    for i in Cs:\n",
    "        model_2 = AdaBoostClassifier(base_estimator=Tree(max_depth=7,min_samples_split=40),n_estimators=i,learning_rate=1,random_state=0)\n",
    "        model_2.fit(x_,y_physical)\n",
    "        pred_i = model_2.predict(features_val)\n",
    "        f_i = f1_score(labels_val_physical, pred_i, average='binary')\n",
    "        if f_i > f_max:\n",
    "            f_max = f_i\n",
    "            pred_2 = pred_i\n",
    "            print(f_i, 'physical',i)\n",
    "    print(' ')\n",
    "    f_max=-1\n",
    "    for i in Cs:\n",
    "        model_3 = AdaBoostClassifier(base_estimator=Tree(max_depth=13,min_samples_split=25),n_estimators=i,learning_rate=1,random_state=0)\n",
    "        model_3.fit(x_,y_sexual)\n",
    "        pred_i = model_3.predict(features_val)\n",
    "        f_i = f1_score(labels_val_sexual, pred_i, average='binary')\n",
    "        if f_i > f_max:\n",
    "            f_max = f_i\n",
    "            pred_3 = pred_i\n",
    "            print(f_i, 'sexual',i)\n",
    "    \n",
    "    return pred_1,pred_2,pred_3\n",
    "    \n",
    "y_pred_ab_1,y_pred_ab_2,y_pred_ab_3 = do_ab(features_train,labels_train_indirect,labels_train_physical,labels_train_sexual,features_val,labels_val)\n",
    "\n",
    "\n",
    "y_pred_ab = y_pred_ab_1 | y_pred_ab_2 | y_pred_ab_3\n",
    "\n",
    "f1_score(labels_val, y_pred_ab, average='binary')\n",
    "#0.3855421686746988"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intercalar y combinar modelos\n",
    "\n",
    "### Rendimiento:\n",
    "\n",
    "#### Regresión logística:\n",
    "0.167 indirect lbfgs c = 1000000\n",
    " \n",
    "0.316 physical newton-cg c = 1000000\n",
    " \n",
    "0.505 sexual saga c = 1000\n",
    "\n",
    "overall: 0.4277456647398844\n",
    "\n",
    "#### Super vector machine:\n",
    "\n",
    "0.211 indirect linear c = 10\n",
    " \n",
    "0.316 physical linear c = 10\n",
    " \n",
    "0.474 sexual linear c = 10\n",
    "\n",
    "overall: 0.4526315789473685\n",
    "\n",
    "#### Árbol regularizado\n",
    "\n",
    "0.270 indirect d = 15 s = 11\n",
    " \n",
    "0.244 physical d = 14 s = 12\n",
    " \n",
    "0.062 sexual d = 11 s = 35\n",
    "\n",
    "overall: 0.18840579710144928\n",
    "\n",
    "#### Random forest \n",
    "\n",
    "0.0 indirect n = 1\n",
    " \n",
    "0.064 physical n = 1\n",
    " \n",
    "0.086 sexual n = 1\n",
    "\n",
    "overall: 0.10144927536231883\n",
    "\n",
    "#### Gradient boost\n",
    "\n",
    "0.190 indirect n = 1\n",
    " \n",
    "0.211 physical n = 2\n",
    " \n",
    "0.554 sexual n = 1\n",
    "\n",
    "overall: 0.5560165975103736\n",
    "\n",
    "#### Adaboost\n",
    "\n",
    "0.171 indirect n = 1\n",
    " \n",
    "0.167 physical n = 1\n",
    " \n",
    "0.435 sexual n =1\n",
    "\n",
    "overall: 0.3726708074534162\n",
    "\n",
    "***Clase 1: TREE > SVM > GB > AB > RL > RF***\n",
    "\n",
    "***Clase 2: RL = SVM > TREE > GB > AB > RF***\n",
    "\n",
    "***Clase 3: GB > RL > SVM > AB > RF > TREE***\n",
    "\n",
    "### Calcular predcciones en test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rl\n",
    "model_1 = LogisticRegression(multi_class='auto',penalty='l2',max_iter=1000,C=1000000,solver = 'lbfgs')\n",
    "model_1.fit(features_train,labels_train_indirect)\n",
    "y_test_logit_1 = model_1.predict(features_test)\n",
    "\n",
    "model_2 = LogisticRegression(multi_class='auto',penalty='l2',max_iter=1000,C=1000000,solver = 'newton-cg')\n",
    "model_2.fit(features_train,labels_train_physical)\n",
    "y_test_logit_2 = model_2.predict(features_test)\n",
    "\n",
    "model_3 = LogisticRegression(multi_class='auto',penalty='l2',max_iter=1000,C=1000,solver = 'saga')\n",
    "model_3.fit(features_train,labels_train_sexual)\n",
    "y_test_logit_3 = model_3.predict(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm\n",
    "model_1 = SVM(kernel='linear',gamma='scale',C=10)\n",
    "model_1.fit(features_train,labels_train_indirect)\n",
    "y_test_svm_1 = model_1.predict(features_test)\n",
    "\n",
    "model_2 = SVM(kernel='linear',gamma='scale',C=10)\n",
    "model_2.fit(features_train,labels_train_physical)\n",
    "y_test_svm_2 = model_2.predict(features_test)\n",
    "\n",
    "model_3 = SVM(kernel='linear',gamma='scale',C=10)\n",
    "model_3.fit(features_train,labels_train_sexual)\n",
    "y_test_svm_3 = model_3.predict(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree\n",
    "model_1 = Tree(max_depth=15, min_samples_split=11)\n",
    "model_1.fit(features_train,labels_train_indirect)\n",
    "y_test_tree_1 = model_1.predict(features_test)\n",
    "\n",
    "model_2 = Tree(max_depth=14, min_samples_split=12)\n",
    "model_2.fit(features_train,labels_train_physical)\n",
    "y_test_tree_2 = model_2.predict(features_test)\n",
    "\n",
    "model_3 = Tree(max_depth=11, min_samples_split=35)\n",
    "model_3.fit(features_train,labels_train_sexual)\n",
    "y_test_tree_3 = model_3.predict(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf\n",
    "model_1 = RandomForestClassifier(n_estimators=1,max_depth=15,min_samples_split=11,random_state=0,n_jobs=-1)\n",
    "model_1.fit(features_train,labels_train_indirect)\n",
    "y_test_rf_1 = model_1.predict(features_test)\n",
    "\n",
    "model_2 = RandomForestClassifier(n_estimators=1,max_depth=14,min_samples_split=12,random_state=0,n_jobs=-1)\n",
    "model_2.fit(features_train,labels_train_physical)\n",
    "y_test_rf_2 = model_2.predict(features_test)\n",
    "\n",
    "model_3 = RandomForestClassifier(n_estimators=1,max_depth=11,min_samples_split=35,random_state=0,n_jobs=-1)\n",
    "model_3.fit(features_train,labels_train_sexual)\n",
    "y_test_rf_3 = model_3.predict(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gb\n",
    "model_1 = GradientBoostingClassifier(n_estimators=1, learning_rate=1.0,max_depth=12,min_samples_split=10, random_state=0)\n",
    "model_1.fit(features_train,labels_train_indirect)\n",
    "y_test_gb_1 = model_1.predict(features_test)\n",
    "\n",
    "model_2 = GradientBoostingClassifier(n_estimators=2, learning_rate=1.0,max_depth=7,min_samples_split=40, random_state=0)\n",
    "model_2.fit(features_train,labels_train_physical)\n",
    "y_test_gb_2 = model_2.predict(features_test)\n",
    "\n",
    "model_3 = GradientBoostingClassifier(n_estimators=1, learning_rate=1.0,max_depth=13,min_samples_split=25, random_state=0)\n",
    "model_3.fit(features_train,labels_train_sexual)\n",
    "y_test_gb_3 = model_3.predict(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ab\n",
    "model_1 = AdaBoostClassifier(base_estimator=Tree(max_depth=12,min_samples_split=10),n_estimators=1,learning_rate=1,random_state=0)\n",
    "model_1.fit(features_train,labels_train_indirect)\n",
    "y_test_ab_1 = model_1.predict(features_test)\n",
    "\n",
    "model_2 = AdaBoostClassifier(base_estimator=Tree(max_depth=7,min_samples_split=40),n_estimators=1,learning_rate=1,random_state=0)\n",
    "model_2.fit(features_train,labels_train_physical)\n",
    "y_test_ab_2 = model_2.predict(features_test)\n",
    "\n",
    "model_3 = AdaBoostClassifier(base_estimator=Tree(max_depth=13,min_samples_split=25),n_estimators=1,learning_rate=1,random_state=0)\n",
    "model_3.fit(features_train,labels_train_sexual)\n",
    "y_test_ab_3 = model_3.predict(features_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejores predicciones por clase (validación):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5726495726495726"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_best = y_pred_tree_1 | y_pred_logit_2 | y_pred_gb_3\n",
    "f1_score(labels_val, y_pred_best, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Votación mayoria por clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probamos 6, por simpleza se removera el con peor fscore por clase para evitar empates\n",
    "\n",
    "clase_1 = list(zip(y_pred_logit_1,y_pred_svm_1,y_pred_tree_1,y_pred_gb_1,y_pred_ab_1))\n",
    "clase_2 = list(zip(y_pred_logit_2,y_pred_svm_2,y_pred_tree_2,y_pred_gb_2,y_pred_ab_2))\n",
    "clase_3 = list(zip(y_pred_logit_3,y_pred_svm_3,y_pred_rf_3,y_pred_gb_3,y_pred_ab_3))\n",
    "\n",
    "def votation(clase):\n",
    "    y_pred = list()\n",
    "    for pred in clase:\n",
    "        #print(pred,max(set(pred), key = pred.count))\n",
    "        y_pred.append(max(set(pred), key = pred.count))\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4550898203592814"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_mayority_1 = votation(clase_1)\n",
    "y_pred_mayority_2 = votation(clase_2)\n",
    "y_pred_mayority_3 = votation(clase_3)\n",
    "\n",
    "y_pred_mayority = y_pred_mayority_1|y_pred_mayority_2|y_pred_mayority_3\n",
    "f1_score(labels_val, y_pred_mayority, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Votación ponderada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5139664804469273"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sera un ranking donde el mejor score vale 5 votos y el peor vale 1 voto\n",
    "\n",
    "weighted_1 = list(zip(y_pred_logit_1,y_pred_svm_1,y_pred_svm_1,y_pred_svm_1,y_pred_svm_1,y_pred_tree_1,y_pred_tree_1,y_pred_tree_1,y_pred_tree_1,y_pred_tree_1,y_pred_gb_1,y_pred_gb_1,y_pred_gb_1,y_pred_ab_1,y_pred_ab_1))\n",
    "weighted_2 = list(zip(y_pred_logit_2,y_pred_logit_2,y_pred_logit_2,y_pred_logit_2,y_pred_logit_2,y_pred_svm_2,y_pred_svm_2,y_pred_svm_2,y_pred_svm_2,y_pred_svm_2,y_pred_tree_2,y_pred_tree_2,y_pred_tree_2,y_pred_tree_2,y_pred_gb_2,y_pred_gb_2,y_pred_gb_2,y_pred_ab_2,y_pred_ab_2))\n",
    "weighted_3 = list(zip(y_pred_logit_3,y_pred_logit_3,y_pred_logit_3,y_pred_logit_3,y_pred_svm_3,y_pred_svm_3,y_pred_svm_3,y_pred_rf_3,y_pred_gb_3,y_pred_gb_3,y_pred_gb_3,y_pred_gb_3,y_pred_gb_3,y_pred_ab_3,y_pred_ab_3))\n",
    "\n",
    "y_pred_weighted_1 = votation(weighted_1)\n",
    "y_pred_weighted_2 = votation(weighted_2)\n",
    "y_pred_weighted_3 = votation(weighted_3)\n",
    "\n",
    "y_pred_weighted = y_pred_weighted_1|y_pred_weighted_2|y_pred_weighted_3\n",
    "f1_score(labels_val, y_pred_weighted, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> El archivo de submission debe contener las predicciones de harassment (0 o 1) a cada dato de pruebas, además de la columna de id asociado al dato, iniciando en 1. Si leyó de manera ordenada el archivo de pruebas, se puede generar de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_1 = list(zip(y_test_logit_1,y_test_svm_1,y_test_tree_1,y_test_gb_1,y_test_ab_1))\n",
    "clase_2 = list(zip(y_test_logit_2,y_test_svm_2,y_test_tree_2,y_test_gb_2,y_test_ab_2))\n",
    "clase_3 = list(zip(y_test_logit_3,y_test_svm_3,y_test_rf_3,y_test_gb_3,y_test_ab_3))\n",
    "y_test_mayority_1 = votation(clase_1)\n",
    "y_test_mayority_2 = votation(clase_2)\n",
    "y_test_mayority_3 = votation(clase_3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weighted_1 = list(zip(y_test_logit_1,y_test_svm_1,y_test_svm_1,y_test_svm_1,y_test_svm_1,y_test_tree_1,y_test_tree_1,y_test_tree_1,y_test_tree_1,y_test_tree_1,y_test_gb_1,y_test_gb_1,y_test_gb_1,y_test_ab_1,y_test_ab_1))\n",
    "weighted_2 = list(zip(y_test_logit_2,y_test_logit_2,y_test_logit_2,y_test_logit_2,y_test_logit_2,y_test_svm_2,y_test_svm_2,y_test_svm_2,y_test_svm_2,y_test_svm_2,y_test_tree_2,y_test_tree_2,y_test_tree_2,y_test_tree_2,y_test_gb_2,y_test_gb_2,y_test_gb_2,y_test_ab_2,y_test_ab_2))\n",
    "weighted_3 = list(zip(y_test_logit_3,y_test_logit_3,y_test_logit_3,y_test_logit_3,y_test_svm_3,y_test_svm_3,y_test_svm_3,y_test_rf_3,y_test_gb_3,y_test_gb_3,y_test_gb_3,y_test_gb_3,y_test_gb_3,y_test_ab_3,y_test_ab_3))\n",
    "\n",
    "y_test_weighted_1 = votation(weighted_1)\n",
    "y_test_weighted_2 = votation(weighted_2)\n",
    "y_test_weighted_3 = votation(weighted_3)\n",
    "\n",
    "\n",
    "\n",
    "y_test_best = y_test_tree_1 | y_test_logit_2 | y_test_gb_3\n",
    "y_test_mayority = y_test_mayority_1|y_test_mayority_2|y_test_mayority_3\n",
    "y_test_weighted = y_test_weighted_1|y_test_weighted_2|y_test_weighted_3\n",
    "\n",
    "\n",
    "\n",
    "df_aux = pd.DataFrame()\n",
    "df_aux[\"id\"] = np.arange(1, 1+y_test_best.shape[0])\n",
    "df_aux[\"harassment\"] = y_test_best.astype('int')\n",
    "df_aux.to_csv(\"test_estimation_best.csv\", index=False)\n",
    "\n",
    "df_aux = pd.DataFrame()\n",
    "df_aux[\"id\"] = np.arange(1, 1+y_test_mayority.shape[0])\n",
    "df_aux[\"harassment\"] = y_test_mayority.astype('int')\n",
    "df_aux.to_csv(\"test_estimation_mayority.csv\", index=False)\n",
    "\n",
    "df_aux = pd.DataFrame()\n",
    "df_aux[\"id\"] = np.arange(1, 1+y_test_weighted.shape[0])\n",
    "df_aux[\"harassment\"] = y_test_weighted.astype('int')\n",
    "df_aux.to_csv(\"test_estimation_weighted.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
